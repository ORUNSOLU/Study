{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n",
    "from pyspark.sql import functions as F \n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.types import IntegerType, StructType, StructField\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "|age|job         |marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|y  |\n",
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "|58 |management  |married|tertiary |no     |2143   |yes    |no  |unknown|5  |may  |261     |1       |-1   |0       |unknown |no |\n",
      "|44 |technician  |single |secondary|no     |29     |yes    |no  |unknown|5  |may  |151     |1       |-1   |0       |unknown |no |\n",
      "|33 |entrepreneur|married|secondary|no     |2      |yes    |yes |unknown|5  |may  |76      |1       |-1   |0       |unknown |no |\n",
      "|47 |blue-collar |married|unknown  |no     |1506   |yes    |no  |unknown|5  |may  |92      |1       |-1   |0       |unknown |no |\n",
      "|33 |unknown     |single |unknown  |no     |1      |no     |no  |unknown|5  |may  |198     |1       |-1   |0       |unknown |no |\n",
      "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.read.csv('bank/bank-full.csv', inferSchema=True, header=True, sep=';')\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Stratified Sampling in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "train, test = df.randomSplit([0.7, 0.3], seed=12345)\n",
    "\n",
    "# for Holdout\n",
    "train, test, holdout = df.randomSplit([0.7, 0.2, 0.1], seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2\n",
    "# this option assumes you used *VectorAssembler\" and there's a column named FEATURES\n",
    "\n",
    "# model initialization\n",
    "lr = LogisticRegression(maxIter=10, featuresCol='features', labelCol='label')\n",
    "\n",
    "# model parameters to try, this is GridSearchCV for PySpark\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.1, 0.01]).addGrid(lr.elasticNetParam,\n",
    "                        [0.0, 0.5, 1.0]).build()\n",
    "\n",
    "# 70% would be used for training, 30% for evaluation\n",
    "train_valid_clf = TrainValidationSplit(estimator=lr, estimatorParamMaps=paramGrid, \n",
    "                            evaluator=BinaryClassificationEvaluator(), trainRatio=0.7)\n",
    "\n",
    "model = train_valid_clf.fit(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3\n",
    "\n",
    "# split data for 0s and 1s\n",
    "zero_df = df.filter(df['label'] == 0)\n",
    "one_df = df.filter(df['label'] == 1)\n",
    "\n",
    "# split data into train & test\n",
    "train_zero, test_zero = zero_df.randomSplit([0.7, 0.3], seed=12345)\n",
    "train_one, test_one = one_df.randomSplit([0.7, 0.3], seed=12345)\n",
    "\n",
    "# unionize datasets\n",
    "train = train_zero.union(train_one)\n",
    "test = test_zero.union(test_one)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-FOLD in Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=10, featuresCol='features', labelCol='label')\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.1, 0.01]).addGrid(\n",
    "    lr.elasticNetParam, [0.0, 0.5, 1.0]).build()\n",
    "\n",
    "# number of folds = 3\n",
    "crossval_clf = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, \n",
    "                    evaluator=BinaryClassificationEvaluator(), numFolds=3)\n",
    "\n",
    "# fit the data\n",
    "model = crossval_clf.fit(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave-one-group out CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.withColumn('label', F.when(F.col('y')=='yes', 1).otherwise(0))\n",
    "df = df.drop('y')\n",
    "df = df.select(['education', 'age', 'balance', 'day', 'duration',\n",
    "                 'campaign', 'pdays', 'previous', 'label'])\n",
    "\n",
    "features_list = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "# function to assemble cols togetger\n",
    "def assemble_vectors(df, features_list, target, group_variable):\n",
    "    stages = []\n",
    "    ve = VectorAssembler(inputCols=features_list, outputCol='features')\n",
    "    stages = [ve]\n",
    "    final_cols = [group_variable, target, 'features']\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    model = pipeline.fit(df)\n",
    "    df = model.transform(df).select(final_cols)\n",
    "    return df\n",
    "    \n",
    "\n",
    "joined_df = assemble_vectors(df, features_list, 'label', 'education')\n",
    "groups = list(joined_df.select('education').toPandas()['education'].unique())\n",
    "\n",
    "def leave_one_group_out_validator(df, var_name, groups):\n",
    "    train_metric_score, test_metric_score = [], []\n",
    "    for i in groups:\n",
    "        train = df.filter(df[var_name] != i)\n",
    "        test = df.filter(df[var_name] != i)\n",
    "        # model initialization\n",
    "        lr = LogisticRegression(maxIter=10, featuresCol='features', labelCol='label')\n",
    "        evaluator = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='rawPrediction',\n",
    "                                            metricName='areaUnderROC')\n",
    "        # fit model\n",
    "        lrModel = lr.fit(train)\n",
    "        # make predictions\n",
    "        predict_train = lrModel.transform(train)\n",
    "        predict_test = lrModel.transform(test)\n",
    "        train_metric_score.append(evaluator.evaluate(predict_train))\n",
    "        test_metric_score.append(evaluator.evaluate(predict_test))\n",
    "        print(str(i) + \"Group evluation\")\n",
    "        print(\" Train AUC - \", train_metric_score[-1])\n",
    "        print(\" Test ROC - \", test_metric_score[-1])\n",
    "    print('Final evaluation for model')\n",
    "    print('Train ROC', np.mean(train_metric_score))\n",
    "    print('Test ROC', np.mean(test_metric_score))        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model assessment for Continous Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating ASSEMBLE_VECTORS function\n",
    "\n",
    "def assemble_vectors(df, features_list, target_variable_name):\n",
    "    stages = []\n",
    "    assembler = VectorAssembler(inputCols=features_list, outputCol='features')\n",
    "    stages = [assembler]\n",
    "    selectedCols = [target_variable_name, 'features'] + features_list\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    assembleModel = pipeline.fit(df)\n",
    "    df = assembleModel.transform(df).select(selectedCols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cSchema = StructType([StructField('x1', IntegerType()), StructField('x2', IntegerType()), StructField('y', IntegerType())])\n",
    "df_list = [[58, 50, 12], [37, 95, 27], [29, 137, 39], [19, 150, 45]]\n",
    "\n",
    "df = spark.createDataFrame(df_list, schema=cSchema)\n",
    "assembled_df = assemble_vectors(df, ['x1', 'x2'], 'y')\n",
    "\n",
    "reg = LinearRegression(featuresCol='features', labelCol='y')\n",
    "reg_model = reg.fit(assembled_df)\n",
    "\n",
    "print(reg_model.coefficients[0], reg_model.intercept)\n",
    "\n",
    "pred_result = reg_model.transform(assembled_df)\n",
    "reg_summary = reg_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Regression Evaluator with MSE\n",
    "\n",
    "# create a dummy prediction results for testing\n",
    "pred_result = ''\n",
    "\n",
    "# just change the METRIC-NAME parameters to try out different metrics\n",
    "evaluator = RegressionEvaluator(labelCol='y', predictionCol='prediction', metricName='mse')\n",
    "evaluator.evaluate(pred_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b7b5a710781a87842cfe8010c06442799678ef166246941c85da77d9a8410c1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
